[project]
name = "mlx8-w3-transformers"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12,<3.14"
dependencies = [
    "torch",
    "pyarrow",
    "torchvision",
    "datasets",
    "tqdm",
    "wandb",
    "colorama",
    "pandas",
    "dotenv",
    "fastapi",
    "uvicorn",
    "numpy",
]

[project.optional-dependencies]
# GPU support for CUDA 12.06 (Ubuntu 22.04) and CUDA 12.8 (Ubuntu 24.04)
gpu = [
    "torch",
    "nvidia-ml-py",
]

# Development tools
dev = [
    "pytest",
    "black", 
    "ruff",
    "mypy",
]

# Full development with GPU
gpu-dev = [
    "mlx8-w3-transformers[gpu,dev]",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
# Platform-specific configurations
dev-dependencies = [
    "pytest",
    "black",
    "ruff",
]

[tool.uv.sources]
# CUDA version detection - defaults to CUDA 12.8, fallback to 12.1
torch = [
    { index = "pytorch-cuda128", marker = "sys_platform == 'linux' and platform_machine == 'x86_64'" },
    { index = "pytorch-cuda121", marker = "sys_platform == 'linux' and platform_machine == 'x86_64'" },
    { index = "pytorch", marker = "sys_platform != 'linux' or platform_machine != 'x86_64'" },
]

[[tool.uv.index]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cpu"

[[tool.uv.index]] 
name = "pytorch-cuda121"
url = "https://download.pytorch.org/whl/cu121"

[[tool.uv.index]]
name = "pytorch-cuda128" 
url = "https://download.pytorch.org/whl/cu128"
